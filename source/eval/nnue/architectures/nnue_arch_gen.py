# NNUE architecture header generator
#
#  NNUEè©•ä¾¡é–¢æ•°ã®architecture headerã‚’å‹•çš„ã«ç”Ÿæˆã™ã‚‹Pythonã§æ›¸ã‹ã‚ŒãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
# 

import argparse
import os

def dedent4(text: str) -> str:
    # å„è¡Œã®å…ˆé ­4æ–‡å­—ï¼ˆã‚¹ãƒšãƒ¼ã‚¹4ã¤ï¼‰ã‚’å‰Šé™¤ã—ã¦çµåˆã—ç›´ã™
    # è¡ŒãŒ4æ–‡å­—æœªæº€ã€ã‚ã‚‹ã„ã¯ã‚¹ãƒšãƒ¼ã‚¹ã§ãªã„å ´åˆã‚’è€ƒæ…®ã—ã¦ lstrip ã§ã‚‚å¯
    return "\n".join(line[4:] if line.startswith("    ") else line 
                        for line in text.strip("\n").splitlines())


print("NNUE architecture header generator by yaneurao V1.02 , 2026/01/31")

parser = argparse.ArgumentParser(description="NNUEã®architecture headerã‚’ç”Ÿæˆã™ã‚‹ã€‚")
parser.add_argument('arch', type=str, nargs='?', default="halfkp_256x2-32-32", help="architectureã‚’æŒ‡å®šã™ã‚‹ã€‚ä¾‹) halfkp_1024x2-8-64, YANEURAOU_ENGINE_NNUE_HALFKP_1024X2_16_32ã¨ã‹")
parser.add_argument('out_dir', type=str, nargs='?', default="", help="å‡ºåŠ›å…ˆã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’æŒ‡å®šã™ã‚‹ã€‚ä¾‹) /source/eval/nnue/architectures/")

args = parser.parse_args()

arch    : str = args.arch
out_dir : str = args.out_dir

# SFNNã§æœ«å°¾ã®ls9ãŒçœç•¥ã•ã‚Œã¦ã„ã‚‹ã£ã½ã„ã®ã§è¶³ã—ã¦ãŠãã€‚
if arch.startswith("SFNN") and not "ls" in arch.lower():
    arch += "_ls9"

# makefileã§æŒ‡å®šã—ãŸã‚¨ãƒ‡ã‚£ã‚·ãƒ§ãƒ³åãã®ã¾ã¾ã‹ã‚‚çŸ¥ã‚Œãªã„ã®ã§å‰Šé™¤
arch   = arch.replace("YANEURAOU_ENGINE_NNUE_","")

# å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
filename = arch + ".h"

# å‡ºåŠ›file path
out_path = os.path.join(out_dir, filename)

print(f"output file path  : {out_path}")

# å¤§æ–‡å­—åŒ–ã—ã¦ã€'-'ã‚’'_'ã«ç½®æ›ã—ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å
arch   = arch.replace('-','_')
arch   = arch.upper()

print(f"architecture name : {arch}")

# if os.path.exists(out_path):
#     print("Warning : file already exists. stop.")
#     exit()
#  ğŸ¤” ãƒ•ã‚¡ã‚¤ãƒ«ãŒã™ã§ã«å­˜åœ¨ã—ã¦ã„ã¦ã‚‚ä¸Šæ›¸ãã—ãŸã»ã†ãŒã„ã„ã¨æ€ã†ã€‚

arches = arch.split('_')
if len(arches) <= 3 :
    # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åã¯ã€ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã¯3ã¤ä»¥ä¸Šãªã„ã¨é§„ç›®ã€‚
    print("Error! : architecture name must be like halfkp_256x2-32-32 or kp_256x2-32-32 halfkpvm_256x2_32_32")
    exit()

# ğŸ“ SFNNwoPSQT_halfkahm_1536-15-32-ls9ã®ã‚ˆã†ã«æŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ã€SFNNã®headerã‚’ç”Ÿæˆã™ã‚‹ã€‚
SFNN = False
if arches[0].startswith("SFNN"):
    SFNN = True
    if len(arches) <= 5 or not arches[5].startswith("LS"):
        # æœ€å¾Œã€"LS9"ã®ã‚ˆã†ãªæ–‡å­—ã§ãªã„ã¨ãŠã‹ã—ã„ã€‚ã‚ã‚‹ã„ã¯çœç•¥ã•ã‚Œã¦ã„ã‚‹ã‹ã€‚
        print("Error! : SFNNwoPSQT architecture name must be like SFNNwoPSQT_halfkahm_1536-15-32-ls9 or SFNNwoPSQT_halfkahm_1536-15-32")
        exit()
    else:
        # å…ˆé ­ã®"LS"ã‚’å‰Šé™¤ã€‚
        arches[5] = arches[5][2:]
    
    # å…ˆé ­ã®"SFNNWOPSQT"å‰Šé™¤
    arches.pop(0)

# ============================================================
#                        includes
# ============================================================

if SFNN:
    header = f"""
    // SFNN without PSQT 1536 architecture

    #ifndef CLASSIC_NNUE_SFNNWOP_{arch}_H_INCLUDED
    #define CLASSIC_NNUE_SFNNWOP_{arch}_H_INCLUDED
    """
else:
    header = f"""
    // Definition of input features and network structure used in NNUE evaluation function
    // NNUEè©•ä¾¡é–¢æ•°ã§ç”¨ã„ã‚‹å…¥åŠ›ç‰¹å¾´é‡ã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã®å®šç¾©
    #ifndef NNUE_{arch}_H_INCLUDED
    #define NNUE_{arch}_H_INCLUDED
    """

# ============================================================
#                     input features
# ============================================================

# ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åã®ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã§splitã—ãŸ1ã¤ç›®ã¯å…¥åŠ›ç‰¹å¾´é‡ã€‚
# ç¾åœ¨ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹å…¥åŠ›ç‰¹å¾´é‡ã¯ã€
#   halfkp
#   kp
#   halfkpe9
#   halfkpvm
#   halfka1
#   halfkahm1
#   halfka2
#   halfkahm2

input_feature = arches[0].lower()

print(f"input feature     : {input_feature}")

header += f"""
    #include "../features/feature_set.h"
    """

if input_feature == "halfkp":

    header += f"""
    #include "../features/half_kp.h"
    """

    raw_features = f"""
        using RawFeatures = Features::FeatureSet<
            Features::HalfKP<Features::Side::kFriend>>;
    """

elif input_feature == "kp":

    header += f"""
    #include "../features/k.h"
    #include "../features/p.h"
    """
    
    raw_features = f"""
        using RawFeatures = Features::FeatureSet<Features::K, Features::P>;
    """

elif input_feature == "halfkpe9":

    header += f"""
    #include "../features/half_kpe9.h"
    """

    raw_features = f"""
        using RawFeatures = Features::FeatureSet<
            Features::HalfKPE9<Features::Side::kFriend>>;
    """

elif input_feature == "halfkpvm":

    header += f"""
    #include "../features/half_kp_vm.h"
    """

    raw_features = f"""
        using RawFeatures = Features::FeatureSet<
            Features::HalfKP_vm<Features::Side::kFriend>>;
    """

elif input_feature == "halfka1":

    header += f"""
    #include "../features/half_ka1.h"
    """

    raw_features = f"""
        using RawFeatures = Features::FeatureSet<
            Features::HalfKA1<Features::Side::kFriend>>;
    """

elif input_feature == "halfkahm1":

    header += f"""
    #include "../features/half_ka_hm1.h"
    """

    raw_features = f"""
        using RawFeatures = Features::FeatureSet<
            Features::HalfKA_hm1<Features::Side::kFriend>>;
    """

elif input_feature == "halfka2":

    header += f"""
    #include "../features/half_ka2.h"
    """

    raw_features = f"""
        using RawFeatures = Features::FeatureSet<
            Features::HalfKA2<Features::Side::kFriend>>;
    """

elif input_feature == "halfkahm2":

    header += f"""
    #include "../features/half_ka_hm2.h"
    """

    raw_features = f"""
        using RawFeatures = Features::FeatureSet<
            Features::HalfKA_hm2<Features::Side::kFriend>>;
    """

else:
    # çŸ¥ã‚‰ãªã„å…¥åŠ›ç‰¹å¾´é‡ã ã£ãŸã€‚
    print(f"Error : input feature {input_feature} is not supported.")
    exit()

if SFNN:
    header += """
    #include <cstring>

    #include "../layers/affine_transform_explicit.h"
    #include "../layers/affine_transform_sparse_input_explicit.h"
    #include "../layers/clipped_relu_explicit.h"
    #include "../layers/sqr_clipped_relu.h"

    namespace YaneuraOu {
    namespace Eval::NNUE {

    // Input features used in evaluation function
    // è©•ä¾¡é–¢æ•°ã§ç”¨ã„ã‚‹å…¥åŠ›ç‰¹å¾´é‡
    """

else:    

    header += """
    #include "../layers/input_slice.h"
    #include "../layers/affine_transform.h"
    #include "../layers/affine_transform_sparse_input.h"
    #include "../layers/clipped_relu.h"

    namespace YaneuraOu {
    namespace Eval::NNUE {

    // Input features used in evaluation function
    // è©•ä¾¡é–¢æ•°ã§ç”¨ã„ã‚‹å…¥åŠ›ç‰¹å¾´é‡
    """

header += raw_features

# ============================================================
#                     hidden layers
# ============================================================

# ãƒ¬ã‚¤ãƒ¤æƒ…å ±
# ä¾‹ãˆã°ã€"256x2_32_32" ãªã‚‰ã° ["256x2","32","32"]ã®ã‚ˆã†ã«åˆ†è§£ã•ã‚Œã‚‹ã€‚
#   (SFNNã§) "1536-15-32-ls9" ãªã‚‰ ["1536","15","32","9"]ã®ã‚ˆã†ã«åˆ†è§£ã•ã‚Œã‚‹ã€‚(ã¯ãš)
layers = arches[1:]
layers[0] = layers[0].lower()

if SFNN:
    if len(layers) != 4:
        print(f"Error : layers must be like 1536-15-32-ls9 , layers = {layers}.")
        exit()

    print(f"layers feature    : {layers}")

    header += f"""

        // Number of input feature dimensions after conversion
        // å¤‰æ›å¾Œã®å…¥åŠ›ç‰¹å¾´é‡ã®æ¬¡å…ƒæ•°
        constexpr IndexType kTransformedFeatureDimensions = {layers[0]};

        // Number of networks stored in the evaluation file
        constexpr int LayerStacks = {layers[3]};

        // å„å±¤ã®æ¬¡å…ƒæ•°
        constexpr IndexType kInputDims   = kTransformedFeatureDimensions;
        constexpr IndexType kHidden1Dims = {layers[1]};
        constexpr IndexType kHidden2Dims = {layers[2]};                              
    """

else:

    if len(layers) != 3 or len(layers[0].split('x')) != 2:
        print(f"Error : layers must be like 256x2-32-32 , layers = {layers}.")
        exit()

    first_layer = layers[0].split('x')

    print(f"layers feature    : {layers}")

    header += f"""
        // Number of input feature dimensions after conversion
        // å¤‰æ›å¾Œã®å…¥åŠ›ç‰¹å¾´é‡ã®æ¬¡å…ƒæ•°
        constexpr IndexType kTransformedFeatureDimensions = {first_layer[0]};

        namespace Layers {{

            // Define network structure
            // ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã®å®šç¾©
            using InputLayer = InputSlice<kTransformedFeatureDimensions * {first_layer[1]}>;
            using HiddenLayer1 = ClippedReLU<AffineTransformSparseInput<InputLayer, {layers[1]}>>;
            using HiddenLayer2 = ClippedReLU<AffineTransform<HiddenLayer1, {layers[2]}>>;
            using OutputLayer = AffineTransform<HiddenLayer2, 1>;

        }}  // namespace Layers
    """

# ============================================================
#                     output layer
# ============================================================

if SFNN:
    # `sfnnwop-1536.h`ã‹ã‚‰ãã®ã¾ã¾ã‚³ãƒ”ãƒšã€‚
    header += f"""
        struct Network {{

            // Define network structure
            // ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã®å®šç¾©
            Layers::AffineTransformSparseInputExplicit<kInputDims, kHidden1Dims + 1> fc_0;
            Layers::ClippedReLUExplicit<kHidden1Dims + 1> ac_0;
            Layers::SqrClippedReLU<kHidden1Dims + 1> ac_sqr_0;

            Layers::AffineTransformExplicit<kHidden1Dims * 2, kHidden2Dims> fc_1;
            Layers::ClippedReLUExplicit<kHidden2Dims> ac_1;
            
        Layers::AffineTransformExplicit<kHidden2Dims, 1> fc_2;

            using OutputType = std::int32_t;
            static constexpr IndexType kOutputDimensions = 1;

            // Hashå€¤ãªã©ã¯é©å®œå®Ÿè£…
            static constexpr std::uint32_t GetHashValue() {{
                return 0x6333718Au;
            }}

            static std::string GetStructureString() {{
                return "{'SFNN-1536' if arch == 'SFNNWOPSQT_HALFKAHM_1536_15_32_LS9' else arch}";
            }}

            Tools::Result ReadParameters(std::istream& stream) {{
                bool result = fc_0.ReadParameters(stream).is_ok()
                    && ac_0.ReadParameters(stream).is_ok()
                    && ac_sqr_0.ReadParameters(stream).is_ok()
                    && fc_1.ReadParameters(stream).is_ok()
                    && ac_1.ReadParameters(stream).is_ok()
                    && fc_2.ReadParameters(stream).is_ok();
                return result ? Tools::ResultCode::Ok : Tools::ResultCode::FileReadError;
            }}

            bool WriteParameters(std::ostream& stream) const {{
                return fc_0.WriteParameters(stream)
                    && ac_0.WriteParameters(stream)
                    && ac_sqr_0.WriteParameters(stream)
                    && fc_1.WriteParameters(stream)
                    && ac_1.WriteParameters(stream)
                    && fc_2.WriteParameters(stream);
            }}

            struct alignas(kCacheLineSize) Buffer {{
                alignas(kCacheLineSize) typename decltype(fc_0)::OutputBuffer fc_0_out;
                alignas(kCacheLineSize) typename decltype(ac_0)::OutputBuffer ac_0_out;
                alignas(kCacheLineSize) typename decltype(ac_sqr_0)::OutputType ac_sqr_0_out[CeilToMultiple<IndexType>(kHidden1Dims * 2, 32)];
                alignas(kCacheLineSize) typename decltype(fc_1)::OutputBuffer fc_1_out;
                alignas(kCacheLineSize) typename decltype(ac_1)::OutputBuffer ac_1_out;
                alignas(kCacheLineSize) typename decltype(fc_2)::OutputBuffer fc_2_out;
            }};

            static constexpr std::size_t kBufferSize = sizeof(Buffer);

            const OutputType* Propagate(const TransformedFeatureType* transformedFeatures, char* buffer) const {{
                auto& buf = *reinterpret_cast<Buffer*>(buffer);

                fc_0.Propagate(transformedFeatures, buf.fc_0_out);
                ac_0.Propagate(buf.fc_0_out, buf.ac_0_out);
                ac_sqr_0.Propagate(buf.fc_0_out, buf.ac_sqr_0_out);
                std::memcpy(buf.ac_sqr_0_out + kHidden1Dims, buf.ac_0_out,
                    kHidden1Dims * sizeof(typename decltype(ac_0)::OutputType));
                fc_1.Propagate(buf.ac_sqr_0_out, buf.fc_1_out);
                ac_1.Propagate(buf.fc_1_out, buf.ac_1_out);
                fc_2.Propagate(buf.ac_1_out, buf.fc_2_out);

                // add shortcut term
                buf.fc_2_out[0] += buf.fc_0_out[kHidden1Dims];

                return buf.fc_2_out;
            }}
        }};

    }}  // namespace Eval::NNUE
    }}  // namespace YaneuraOu

    #endif // CLASSIC_NNUE_{arch}_H_INCLUDED
    """

    # ğŸ’¡ GetStructureString()ã§ç•°ãªã‚‹æ–‡å­—åˆ—ã‚’è¿”ã™ã¨åˆ¥ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã¿ãªã•ã‚Œã¦ã—ã¾ã†ã€‚

else:
    header += f"""
        using Network = Layers::OutputLayer;

    }} // namespace Eval::NNUE
    }} // namespace YaneuraOu

    #endif // #ifndef NNUE_{arch}_H_INCLUDED
    """

with open(out_path, "w", encoding = 'utf-8') as f:
    f.write(dedent4(header))

print("..done!")
